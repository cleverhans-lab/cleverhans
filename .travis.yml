# adapted from https://github.com/fchollet/keras/blob/master/.travis.yml
sudo: required
dist: trusty
language: python
python:
  - 3.5
env:
  - KERAS_BACKEND=tensorflow TENSORFLOW_V=1.8.0 PYTORCH=True
  - KERAS_BACKEND=tensorflow TENSORFLOW_V=1.12.0 PYTORCH=True
  - KERAS_BACKEND=tensorflow TENSORFLOW_V=1.8.0 PYTORCH=True

install:
  # code below is taken from http://conda.pydata.org/docs/travis.html
  - wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh;
  - bash miniconda.sh -b -p $HOME/miniconda
  - export PATH="$HOME/miniconda/bin:$PATH"
  - hash -r
  - conda config --set always_yes yes --set changeps1 no
  - conda update -q conda
  # Useful for debugging any issues with conda
  - conda info -a

  - conda create -q -n test-environment python=$TRAVIS_PYTHON_VERSION pandas h5py six mkl-service
  - source activate test-environment
  - pip install numpy
  - pip install scipy
  - pip install matplotlib

  # install TensorFlow
  - if [[ "$TRAVIS_PYTHON_VERSION" == "3.5" && "$TENSORFLOW_V" == "1.8.0" ]]; then
      pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.8.0-cp35-cp35m-linux_x86_64.whl;
    elif [[ "$TRAVIS_PYTHON_VERSION" == "3.5" && "$TENSORFLOW_V" == "1.12.0" ]]; then
      pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.12.0rc1-cp35-cp35m-linux_x86_64.whl;
    fi

  - time pip install -q -e ".[test]"
  - if [[ "$PYTORCH" == True ]]; then
      pip install torch==1.0.1.post2 torchvision==0.2.2 -q;
    fi
  # workaround for version incompatibility between the scipy version in conda
  # and the system-provided /usr/lib/x86_64-linux-gnu/libstdc++.so.6
  # by installing a conda-provided libgcc and adding it to the load path
  - conda install libgcc
  - export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/travis/miniconda/envs/test-environment/lib

  # install serialization dependencies
  - pip install joblib
  # install dependencies for adversarial competition eval infra tests
  - pip install google-cloud==0.33.1
  - pip install Pillow
  # Style checks
  - pip install pylint==1.9.3
  # To be able to exclude subdirectories in nose tests
  - pip install nose-exclude

# command to run tests
script:
  # exit on first error
  - set -e
  # run keras backend init to initialize backend config
  - python -c "from tensorflow import keras"
  # create dataset directory to avoid concurrent directory creation at runtime
  - mkdir ~/.keras/datasets
  # set up keras backend
  - sed -i -e 's/"backend":[[:space:]]*"[^"]*/"backend":\ "'$KERAS_BACKEND'/g' ~/.keras/keras.json;
  - echo -e "Running tests with the following config:\n$(cat ~/.keras/keras.json)"
  # test for evaluation infrastructure are very fast, so running them first
  - nosetests -v --nologcapture -w examples/nips17_adversarial_competition/eval_infra/code/ eval_lib/tests/
  #
  # --nologcapture: avoids a large amount of unnecessary tensorflow output
  # --stop: stop on first error. Gives feedback from travis faster
  #
  # Tests for certification code require Tensorflow 1.9 or higher,
  # thus skipping these tests for lower version of Tensorflow.
  - if [[ "$PYTORCH" == True ]]; then
      nosetests --nologcapture -v --stop cleverhans/future/torch/tests;
    elif [[ "$PYTORCH" == False ]]; then
      if [[ "$TENSORFLOW_V" == "1.8.0" ]]; then
        nosetests -v --nologcapture --stop --exclude-dir=cleverhans/experimental/certification cleverhans;
      else
        nosetests -v --nologcapture --stop cleverhans;
      fi;
      for test_path in tests_tf/*.py ; do
        nosetests --nocapture -v --stop $test_path;
      done
    fi
